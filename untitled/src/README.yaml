- 三级管理机构：OS->heap->central->cache
- heap：GC管理的对象
- 辅助对象：spans->bitmap->arena
- 不同版本的go，页的大小也不一样，不能和OS的直接对等。
- central没有空间分配给cache时向heap申请，heap没有再向OS申请
- central一次分配给cache一批，具体多少不是动态算法，写死的（分配时加锁，但是粒度降低了）

base on tcmalloc:以空间换时间，减少锁对多核的影响

1: 内存分配器（Memory Allocator）
 - 只扫描arena区域
 - 主要操作小于32k的小对象
 - 指针、内存地址等大部分都是8k的倍数，因此只要管理60多个缓存策略即可
 - version1.2: cache长度超过一定长度后触发，1.3之后改为由GC来触发
 - 对象空间回收:
    - 大对象: 被标记后把空间直接还给heap（堆）
    - 小对象: cache的空间被标记后，central上的空间快出现两种状态
        - central的磁盘块全部回收: 交换给heap（堆）
        - central的磁盘块部分回收: 不交换给heap（堆），由其他cache现成继续申请
    - heap: 对于cache交还的空间块，内存分配器并不交换给OS，且不做任何处理


2: Garbage Collector
  - 并行标记、并行清理（标记后回复逻辑，清理任务（新的goroutine）和逻辑同时执行）,把暂停时间由标记+清理变成只有标记用时
  - 三种触发方式:
      - 分配对象的数目超过一定数量以后就会触发
      - 如果长时间没触发会强制GC一次
      - 手动调用触发，如果手动触发会把标记和清楚变成串行的，清理不会和逻辑并行（不建议）
  - GC只是建议OS接触虚拟-物理地址映射，如果内存占用率不高OS可能不会解除，造成GC后使用的内存不变


3: Goroutine Schedule
  - go: 任务（goroutine）和线程是多对多模型，CPU本身优化策略无效，所以CPU密集型应用效率不高；但如果写的是I/O密集型应用，CPU占用率不高，一对一模型优势不好go官方的模型很好，I/O阻塞时可以干其他事情
  - Schedule核心:
      - M：Thread；最大10000，超过时进程直接崩溃
      - P：虚拟机CPU核数，不一定和物理核数一致；最终执行的时候和go关于P的参数有关，如果是1，即使是2核，也只会有一个线程；P和M是一对一的
      - G：goroutine（task），什么时候执行由go决定；包括函数、参数、栈（包括g0栈），G对象是可以复用的；创建的时候是仍到P队列的，而不是M队列，P队列由长度限制；超出P队列长度时会被转移到全局队列供其他P队列执行







内存管理 数据速度最快?
析构函数？finalize()生命周期被拉长